{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBLfk9LDOISy",
        "8HQa3xBROQGB",
        "UGfUzaQLPQGV",
        "v1r9C2OBPiI3",
        "P4JwZsHiPtci"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fariasfranco/ClasificadordeCanciones/blob/main/Clasificador_de_canciones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 1: Inicio Programa\n",
        "####En este primer paso se importan las bibliotecas necesarias para el proyecto, Estas bibliotecas incluyen \"pandas\" para el manejo de datos, \"train_test_split\" para dividir los datos en conjuntos de entrenamiento y prueba, y varias bibliotecas de modelos de aprendizaje automático como \"KNeighborsClassifier\", \"SVC\", \"DecisionTreeClassifier\", \"GaussianNB\", y \"VotingClassifier\".Donde tambien se utiliza \"GridSearchCV\" para realizar una búsqueda de cuadrícula en el ajuste de hiperparámetros y varias métricas de evaluación de modelos, como \"accuracy_score\", \"confusion_matrix\", \"precision_score\", \"recall_score\" y \"f1_score\".\n",
        "####Luego se carga el archivo de base de datos .CSV  llamado \"Canciones_Spotify.csv\" en un DataFrame de \"pandas\" llamado \"data0\"."
      ],
      "metadata": {
        "id": "FBLfk9LDOISy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPmgZ7O4kRQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import numpy as np  # Importa la biblioteca numpy\n",
        "\n",
        "#Cargar el conjunto de datos\n",
        "csv_file_url = \"/content/Canciones_Spotify.csv\"\n",
        "data0 = pd.read_csv(csv_file_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 2: PreProcesamiento de Datos\n",
        "####En este paso, se ha preparado el conjunto de datos para que pueda ser utilizado en la construcción de modelos de machine learning. Las características se han codificado y separado de las etiquetas, lo que es esencial para el entrenamiento y evaluación de los modelos.Lo cual esto implica la codificación de \"variables categóricas\" y la \"separación de las características\" (variables independientes) y las etiquetas (variable dependiente).\n",
        "####\"Variables Categóricas\": En este paso, se toman las columnas \"artist\" y \"song_title\", que son variables categóricas, y se aplican técnicas de codificación. En este caso, se utiliza el método conocido como \"one-hot encoding\". Lo que hace esta técnica es convertir cada categoría única en estas columnas en una nueva columna binaria. Cada columna binaria representa si una canción pertenece a una categoría particular o no. Esto ayuda a los modelos de machine learning a trabajar con estas características categóricas.\n",
        "####\"Separación de Características (X) y Etiquetas (y)\": Después de codificar las variables categóricas, el conjunto de datos se divide en dos partes:\n",
        "\n",
        "####X: Este es el conjunto de características. Contiene todas las columnas excepto la columna \"target\", que es la etiqueta que queremos predecir. En otras palabras, X contiene las características que se utilizarán para hacer predicciones sobre las preferencias de las canciones.\n",
        "####y: Esta es la etiqueta que se quiere predecir. En este caso, la columna \"target\" que indica si una canción fue del agrado del usuario (1) o no (0)."
      ],
      "metadata": {
        "id": "8HQa3xBROQGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento de datos\n",
        "# Codificar variables categóricas (artist y song_title) utilizando one-hot encoding\n",
        "data = pd.get_dummies(data0, columns=[\"artist\", \"song_title\"])\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X = data.drop(columns=[\"target\"])\n",
        "y = data[\"target\"]\n"
      ],
      "metadata": {
        "id": "X85BEnVfO0cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 3: Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "####En ese terceer paso dividimos los datos en conjuntos de entrenamiento y prueba. Utilizamos la función \"train_test_split\" de la biblioteca \"scikit-learn\" para realizar esta división.El conjunto de entrenamiento (X_train y y_train) se utiliza para entrenar nuestros modelos de machine learning, mientras que el conjunto de prueba (X_test y y_test) se utiliza para evaluar el rendimiento de los modelos.\n",
        "####1.X_train:contiene las características del conjunto de entrenamiento.\n",
        "####2.X_test:contiene las características del conjunto de prueba.\n",
        "####3.y_train:contiene las etiquetas del conjunto de entrenamiento.\n",
        "####4.y_test:contiene las etiquetas del conjunto de prueba.\n",
        "####Se configuro el parametro \"test_size\" en 0.2, lo que significa que el 20% de los datos se utilizarán como conjunto de prueba, y el 80% restante se utilizará como conjunto de entrenamiento. También se establecio \"random_state\" en 42 para garantizar la reproducibilidad de la división de datos."
      ],
      "metadata": {
        "id": "UGfUzaQLPQGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "S8pxUjs8PVNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 4: Entrenar modelos de machine learning\n",
        "####Se entrena algunos modelos de machine learning.Primero,se definio una variable llamada \"evaluate_model\" que ayuda a evaluar la precisión de un modelo utilizando validación cruzada (cross_val_score) con 5 particiones. Luego, se importa varios modelos de \"scikit-learn\" que incluyen \"K-Nearest Neighbors (KNN)\", \"Support Vector Machines (SVM)\", \"Árbol de Decisión\", \"Naive Bayes\" y \"Random Forest\".\n",
        "####En este paso, también se selecciona un conjunto de características importantes para entrenar nuestros modelos. Estas características incluyen \"danceability\", \"energy\", \"valence\", \"acousticness\", \"instrumentalness\", \"tempo\" y \"speechiness\".\n",
        "####Después de filtrar los conjunto de datos de entrenamiento y prueba con estas características seleccionadas, se itera a través de cada modelo y se calcula su precisión utilizando la función \"evaluate_model\". Luego, hemos realizado una búsqueda de hiperparámetros (Grid Search) para el modelo KNN para encontrar los mejores valores para los hiperparámetros 'n_neighbors', 'weights' y 'p'. Los mejores modelos se han almacenado en el diccionario \"best_models\"."
      ],
      "metadata": {
        "id": "v1r9C2OBPiI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "def evaluate_model(model, X, y):\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    return scores.mean()\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "svm = SVC()\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "naive_bayes = GaussianNB()\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "# Define las características que deseas utilizar\n",
        "important_features = [\"danceability\", \"energy\", \"valence\", \"acousticness\", \"instrumentalness\", \"tempo\", \"speechiness\"]\n",
        "\n",
        "# Filtra el conjunto de datos con las características seleccionadas\n",
        "X_train = X_train[important_features]\n",
        "X_test = X_test[important_features]\n",
        "\n",
        "models = {\n",
        "    \"KNN\": knn,\n",
        "    \"SVM\": svm,\n",
        "    \"Decision Tree\": decision_tree,\n",
        "    \"Naive Bayes\": naive_bayes,\n",
        "    \"Random Forest\": random_forest,\n",
        "}\n",
        "\n",
        "best_models = {}  # Almacenar los mejores modelos para cada tipo de modelo\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    accuracy = evaluate_model(model, X_train, y_train)\n",
        "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, scoring='accuracy', cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_models[model_name] = grid_search.best_estimator_\n",
        "best_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwZF4shRoI7X",
        "outputId": "1d58d591-8ee0-490f-b385-bd66883b8ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.5815145280079995\n",
            "SVM Accuracy: 0.5337884352825799\n",
            "Decision Tree Accuracy: 0.6763744399361575\n",
            "Naive Bayes Accuracy: 0.6317308616810569\n",
            "Random Forest Accuracy: 0.7526508086071957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Random Forest': KNeighborsClassifier(n_neighbors=3, p=1, weights='distance')}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 5: Ajustar y evaluar modelos de machine learning\n",
        "####Este Paso 5 se enfoca en ajustar y evaluar los modelos de machine learning que has entrenado anteriormente.\n",
        "####evaluate_model_performance: Esta función evalúa el rendimiento de un modelo. Calcula la matriz de confusión, la precisión, la recuperación y el puntaje F1 del modelo en el conjunto de prueba.\n",
        "\n",
        "####Loop sobre los modelos: Un bucle for se utiliza para iterar a través de los modelos que has entrenado en el Paso 4. Para cada modelo:\n",
        "\n",
        "#####Se ajusta el modelo utilizando los datos de entrenamiento con model.fit(X_train, y_train).\n",
        "\n",
        "#####Se evalúa el rendimiento del modelo en el conjunto de prueba utilizando evaluate_model_performance.\n",
        "\n",
        "#####Los resultados, incluyendo la matriz de confusión, precisión, recuperación y puntaje F1, se imprimen para cada modelo.\n",
        "\n",
        "####Seguimiento del mejor modelo: Se realiza un seguimiento del mejor modelo en términos de puntaje F1. Si un modelo tiene un puntaje F1 más alto que el actual mejor modelo, se actualiza best_model_name con el nombre del nuevo mejor modelo y se almacena el modelo en el diccionario best_models.\n",
        "\n",
        "####Mejor modelo: Finalmente, se imprime el nombre del mejor modelo basado en el puntaje F1.\n",
        "####En resumen este paso ayuda a identificar cuál de los modelos tiene el mejor rendimiento en términos de F1-score, lo que puede ser útil para seleccionar el modelo final."
      ],
      "metadata": {
        "id": "P4JwZsHiPtci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_performance(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    return conf_matrix, precision, recall, f1\n",
        "\n",
        "best_models = {}  # Almacenar los mejores modelos para cada tipo de modelo\n",
        "best_f1 = 0  # Almacenar el mejor valor de F1\n",
        "best_model_name = None  # Almacenar el nombre del mejor modelo\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Ajustar el modelo con los datos de entrenamiento\n",
        "    model.fit(X_train, y_train)\n",
        "    # Evaluar el rendimiento del modelo en el conjunto de prueba\n",
        "    conf_matrix, precision, recall, f1 = evaluate_model_performance(model, X_test, y_test)\n",
        "    print(f\"{model_name} Performance:\")\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1-score:\", f1)\n",
        "\n",
        "    # Si es el mejor modelo hasta el momento, actualiza best_model_name y best_f1\n",
        "    if best_model_name is None or f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model_name = model_name\n",
        "\n",
        "    # Almacena el mejor modelo en el diccionario best_models\n",
        "    best_models[model_name] = model\n",
        "\n",
        "print(f\"Mejor modelo: {best_model_name}\")"
      ],
      "metadata": {
        "id": "c4bPjHy5pIs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b19b25-0da0-4434-d9da-9c89cd066732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Performance:\n",
            "Confusion Matrix:\n",
            " [[130  76]\n",
            " [ 84 114]]\n",
            "Precision: 0.6\n",
            "Recall: 0.5757575757575758\n",
            "F1-score: 0.5876288659793815\n",
            "SVM Performance:\n",
            "Confusion Matrix:\n",
            " [[ 53 153]\n",
            " [ 41 157]]\n",
            "Precision: 0.5064516129032258\n",
            "Recall: 0.7929292929292929\n",
            "F1-score: 0.6181102362204725\n",
            "Decision Tree Performance:\n",
            "Confusion Matrix:\n",
            " [[139  67]\n",
            " [ 59 139]]\n",
            "Precision: 0.6747572815533981\n",
            "Recall: 0.702020202020202\n",
            "F1-score: 0.6881188118811882\n",
            "Naive Bayes Performance:\n",
            "Confusion Matrix:\n",
            " [[121  85]\n",
            " [ 60 138]]\n",
            "Precision: 0.6188340807174888\n",
            "Recall: 0.696969696969697\n",
            "F1-score: 0.655581947743468\n",
            "Random Forest Performance:\n",
            "Confusion Matrix:\n",
            " [[151  55]\n",
            " [ 50 148]]\n",
            "Precision: 0.729064039408867\n",
            "Recall: 0.7474747474747475\n",
            "F1-score: 0.7381546134663343\n",
            "Mejor modelo: Random Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 6: Realizar un ensamble de los modelos (Votación Mayoritaria)\n",
        "####Este paso crea un modelo de ensamble que combina las predicciones de varios modelos individuales. El ensamble puede ayudar a mejorar el rendimiento y la estabilidad de las predicciones finales.\n",
        "####Votación Mayoritaria: La votación mayoritaria es un método de ensamble que combina las predicciones de varios modelos de machine learning para tomar una decisión final. En este caso, se utiliza la clase \"VotingClassifier\" de \"scikit-learn\" para implementar esta técnica.\n",
        "\n",
        "####Configuración del Ensamble: se configura el ensamble con varios modelos, incluyendo KNN, SVM, Árbol de Decisión, Naive Bayes y Random Forest. Los modelos se pasan como estimadores en una lista. La opción voting=\"hard\" indica que se tomará la decisión final basada en la mayoría de votos de los modelos.\n",
        "\n",
        "####Ajuste del Ensamble: se ajusta el modelo de ensamble con los datos de entrenamiento utilizando ensemble.fit(X_train, y_train)."
      ],
      "metadata": {
        "id": "ZOuZjBDfqNEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble = VotingClassifier(estimators=[(\"KNN\", best_models[\"KNN\"]), (\"SVM\", best_models[\"SVM\"]), (\"Decision Tree\", best_models[\"Decision Tree\"]), (\"Naive Bayes\", best_models[\"Naive Bayes\"]), (\"Random Forest\", best_models[\"Random Forest\"])], voting=\"hard\")\n",
        "ensemble.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCLtt5EQqU5o",
        "outputId": "f6672dfc-a233-4da3-d286-16f71230a2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('KNN', KNeighborsClassifier()), ('SVM', SVC()),\n",
              "                             ('Decision Tree', DecisionTreeClassifier()),\n",
              "                             ('Naive Bayes', GaussianNB()),\n",
              "                             ('Random Forest', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;KNN&#x27;, KNeighborsClassifier()), (&#x27;SVM&#x27;, SVC()),\n",
              "                             (&#x27;Decision Tree&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;Naive Bayes&#x27;, GaussianNB()),\n",
              "                             (&#x27;Random Forest&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;KNN&#x27;, KNeighborsClassifier()), (&#x27;SVM&#x27;, SVC()),\n",
              "                             (&#x27;Decision Tree&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;Naive Bayes&#x27;, GaussianNB()),\n",
              "                             (&#x27;Random Forest&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>KNN</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Decision Tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Naive Bayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 7: Evaluación y análisis del rendimiento del ensamble\n",
        "####Este paso proporciona una evaluación completa del rendimiento del ensamble, lo que te permite comprender cuán efectivo es en la tarea de categorizar canciones según las preferencias del usuario."
      ],
      "metadata": {
        "id": "P0pm6C0SqicR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix, precision, recall, f1 = evaluate_model_performance(ensemble, X_test, y_test)\n",
        "print(\"Ensemble Performance:\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuMbRuujqhsu",
        "outputId": "18349b87-fd10-4c3b-bddd-8f1130b3493f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Performance:\n",
            "Confusion Matrix:\n",
            " [[133  73]\n",
            " [ 43 155]]\n",
            "Precision: 0.6798245614035088\n",
            "Recall: 0.7828282828282829\n",
            "F1-score: 0.727699530516432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extras\n",
        "####Este paso proporciona una experiencia práctica al usuario, ya que simula la funcionalidad de una aplicación de recomendación de canciones.\n",
        "####Selección de una Canción Aleatoria: El código elige aleatoriamente una canción de las que le gustan al usuario a partir del conjunto de datos. Esto simula la idea de seleccionar una canción de la que al usuario le guste para luego recibir recomendaciones similares.\n",
        "\n",
        "####Predicción de Canciones Sugeridas: Utiliza el mejor modelo de aprendizaje automático entrenado anteriormente para predecir una canción sugerida basada en las características de la canción aleatoria elegida. El modelo toma las características de la canción aleatoria y hace una predicción sobre qué otras canciones le podrían gustar al usuario.\n",
        "\n",
        "####Selección de Canciones Sugeridas Aleatorias: El código crea una lista de canciones sugeridas que se predice que le gustarán al usuario. Luego, selecciona una de estas canciones sugeridas al azar para recomendar.\n",
        "\n",
        "####Impresión de Resultados: Imprime la canción que le gusta al usuario y la canción sugerida, si se encuentra una recomendación adecuada. Si no hay recomendaciones disponibles, muestra un mensaje informativo"
      ],
      "metadata": {
        "id": "nKHlvHVxQaiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Elegir una canción aleatoria de las que le gusta al usuario desde el conjunto de datos\n",
        "canciones_gustadas = data0[data0[\"target\"] == 1][[\"song_title\", \"artist\"]]\n",
        "canciones_gustadas = list(canciones_gustadas.itertuples(index=False, name=None))\n",
        "cancion_aleatoria_info = random.choice(canciones_gustadas)\n",
        "cancion_aleatoria = cancion_aleatoria_info[0]\n",
        "artista_cancion_gusta = cancion_aleatoria_info[1]\n",
        "\n",
        "# Imprimir la canción elegida que le gusta al usuario\n",
        "print(f\"Canción que te gusta: {cancion_aleatoria} (Artista: {artista_cancion_gusta})\")\n",
        "\n",
        "# Obtener las características de la canción aleatoria\n",
        "cancion_aleatoria_features = data0[data0[\"song_title\"] == cancion_aleatoria][important_features]\n",
        "\n",
        "# Utilizar el mejor modelo de aprendizaje automático para predecir una canción sugerida\n",
        "resultado_predicción = best_models[best_model_name].predict(cancion_aleatoria_features)\n",
        "\n",
        "# Obtener una lista de canciones que el modelo predice que le gustarán al usuario\n",
        "canciones_sugeridas = []\n",
        "\n",
        "for song_title, artist in zip(data0[\"song_title\"], data0[\"artist\"]):\n",
        "    song_features = data0[data0[\"song_title\"] == song_title][important_features]\n",
        "    prediction = best_models[best_model_name].predict(song_features)\n",
        "    if np.any(prediction == 1) and song_title != cancion_aleatoria:\n",
        "        canciones_sugeridas.append((song_title, artist))\n",
        "\n",
        "# Seleccionar una de las canciones sugeridas aleatoriamente\n",
        "if canciones_sugeridas:\n",
        "    cancion_sugerida = random.choice(canciones_sugeridas)\n",
        "    print(f\"Canción sugerida: {cancion_sugerida[0]} (Artista: {cancion_sugerida[1]})\")\n",
        "else:\n",
        "    print(\"Lo sentimos, no tenemos recomendaciones en este momento.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeKOvO5PxIAO",
        "outputId": "c888cc3b-caf0-48cf-b5aa-1124b32e6bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canción que te gusta: Don't Mean A Thing (Artista: Lapalux)\n",
            "Canción sugerida: Myth (Artista: Beach House)\n"
          ]
        }
      ]
    }
  ]
}